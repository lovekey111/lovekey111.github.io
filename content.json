{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/05/14/hello-world/"},{"title":"机器学习相关问题","text":"1、逻辑回归(LR)公式推导Logistic函数(sigmoid函数): $f(x)=\\frac{1}{1+e^{-z}}$ Logistic函数求导: $\\frac{df(x)}{dz}=\\frac{e^{-z}}{(1+e^{-z})^{2}}$ $=\\frac{1}{1+e^{-z}}(1-\\frac{1}{1+e^{-z}})$ $=f(x)(1-f(x))$ 逻辑回归表达式逻辑回归条件概率分布合并为 梯度下降极大似然估计 2、L1、L2正则化L1正则化(Lasso回归)： 易获得稀疏解，导致W中多项变成零； 稀疏解可以减小计算量并选择特征，使得特征选择与学习器训练过程融为一体，同时完成； 由于特征选择，使得模型可解释性较强。 L2正则化(岭回归)： 使W的每个元素都很小，接近于0，使得参数比较均衡； 由于参数较均衡，防止模型对某特征过于敏感。","link":"/2019/05/16/机器学习相关问题/"}],"tags":[{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"}],"categories":[{"name":"machine learning","slug":"machine-learning","link":"/categories/machine-learning/"}]}